{
    "name": "root",
    "gauges": {
        "Player.Policy.Entropy.mean": {
            "value": 2.7563703060150146,
            "min": 2.638205051422119,
            "max": 3.092761516571045,
            "count": 221
        },
        "Player.Policy.Entropy.sum": {
            "value": 4878.775390625,
            "min": 81.9291000366211,
            "max": 15082.9658203125,
            "count": 221
        },
        "Player.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 221
        },
        "Player.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 221
        },
        "Player.Step.mean": {
            "value": 1234970.0,
            "min": 1015974.0,
            "max": 1234970.0,
            "count": 220
        },
        "Player.Step.sum": {
            "value": 1234970.0,
            "min": 1015974.0,
            "max": 1234970.0,
            "count": 220
        },
        "Player.Policy.ExtrinsicValueEstimate.mean": {
            "value": 1.6147745847702026,
            "min": -0.666028618812561,
            "max": 3.6215288639068604,
            "count": 220
        },
        "Player.Policy.ExtrinsicValueEstimate.sum": {
            "value": 14.532971382141113,
            "min": -6.660285949707031,
            "max": 32.28334426879883,
            "count": 220
        },
        "Player.Environment.EpisodeLength.mean": {
            "value": 810.0,
            "min": 35.0,
            "max": 1257.0,
            "count": 143
        },
        "Player.Environment.EpisodeLength.sum": {
            "value": 1620.0,
            "min": 140.0,
            "max": 8582.0,
            "count": 143
        },
        "Player.Losses.PolicyLoss.mean": {
            "value": 0.09496291996038053,
            "min": 0.08433710342893998,
            "max": 0.10977729223086499,
            "count": 102
        },
        "Player.Losses.PolicyLoss.sum": {
            "value": 0.09496291996038053,
            "min": 0.08433710342893998,
            "max": 0.10977729223086499,
            "count": 102
        },
        "Player.Losses.ValueLoss.mean": {
            "value": 0.4709298704750836,
            "min": 0.2793188399635255,
            "max": 0.933124231930935,
            "count": 102
        },
        "Player.Losses.ValueLoss.sum": {
            "value": 0.4709298704750836,
            "min": 0.2793188399635255,
            "max": 0.933124231930935,
            "count": 102
        },
        "Player.Policy.LearningRate.mean": {
            "value": 0.00020977993251239028,
            "min": 0.00020977993251239028,
            "max": 0.00022545441509243906,
            "count": 102
        },
        "Player.Policy.LearningRate.sum": {
            "value": 0.00020977993251239028,
            "min": 0.00020977993251239028,
            "max": 0.00022545441509243906,
            "count": 102
        },
        "Player.Policy.Epsilon.mean": {
            "value": 0.16992663414634146,
            "min": 0.16992663414634146,
            "max": 0.1751514634146342,
            "count": 102
        },
        "Player.Policy.Epsilon.sum": {
            "value": 0.16992663414634146,
            "min": 0.16992663414634146,
            "max": 0.1751514634146342,
            "count": 102
        },
        "Player.Policy.Beta.mean": {
            "value": 0.003499339043902439,
            "min": 0.003499339043902439,
            "max": 0.003760058024390244,
            "count": 102
        },
        "Player.Policy.Beta.sum": {
            "value": 0.003499339043902439,
            "min": 0.003499339043902439,
            "max": 0.003760058024390244,
            "count": 102
        },
        "Player.Self-play.ELO.mean": {
            "value": 1344.7752835246874,
            "min": 1334.025739991347,
            "max": 1350.3307295449545,
            "count": 142
        },
        "Player.Self-play.ELO.sum": {
            "value": 1344.7752835246874,
            "min": 1334.025739991347,
            "max": 9423.562057651956,
            "count": 142
        },
        "Player.Environment.CumulativeReward.mean": {
            "value": -6.693399980664253,
            "min": -14.853999614715576,
            "max": 27.355499178171158,
            "count": 178
        },
        "Player.Environment.CumulativeReward.sum": {
            "value": -6.693399980664253,
            "min": -39.08129942417145,
            "max": 81.06680190563202,
            "count": 178
        },
        "Player.Policy.ExtrinsicReward.mean": {
            "value": -6.693399980664253,
            "min": -14.853999614715576,
            "max": 27.355499178171158,
            "count": 178
        },
        "Player.Policy.ExtrinsicReward.sum": {
            "value": -6.693399980664253,
            "min": -39.08129942417145,
            "max": 81.06680190563202,
            "count": 178
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1717013071",
        "python_version": "3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\emi02\\Tennis Project\\venv\\Scripts\\mlagents-learn Files_Yaml/Tennis.yaml --run-id=Final_Train --resume",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.2+cpu",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1717013610"
    },
    "total": 538.4860542999813,
    "count": 1,
    "self": 0.006118499906733632,
    "children": {
        "run_training.setup": {
            "total": 0.07665240007918328,
            "count": 1,
            "self": 0.07665240007918328
        },
        "TrainerController.start_learning": {
            "total": 538.4032833999954,
            "count": 1,
            "self": 0.6242895992472768,
            "children": {
                "TrainerController._reset_env": {
                    "total": 20.580890999990515,
                    "count": 4,
                    "self": 20.580890999990515
                },
                "TrainerController.advance": {
                    "total": 517.037411600817,
                    "count": 15244,
                    "self": 0.20570430834777653,
                    "children": {
                        "env_step": {
                            "total": 516.8317072924692,
                            "count": 15244,
                            "self": 404.4620643812232,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 112.16842191107571,
                                    "count": 15244,
                                    "self": 2.1907342084450647,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 109.97768770263065,
                                            "count": 29902,
                                            "self": 109.97768770263065
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.20122100017033517,
                                    "count": 15243,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 517.9820023016073,
                                            "count": 15243,
                                            "is_parallel": true,
                                            "self": 175.87426390557084,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0025634001940488815,
                                                    "count": 8,
                                                    "is_parallel": true,
                                                    "self": 0.0013587001012638211,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0012047000927850604,
                                                            "count": 16,
                                                            "is_parallel": true,
                                                            "self": 0.0012047000927850604
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 342.1051749958424,
                                                    "count": 15243,
                                                    "is_parallel": true,
                                                    "self": 3.2619792065816,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 6.712787791388109,
                                                            "count": 15243,
                                                            "is_parallel": true,
                                                            "self": 6.712787791388109
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 321.70441329758614,
                                                            "count": 15243,
                                                            "is_parallel": true,
                                                            "self": 321.70441329758614
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 10.425994700286537,
                                                            "count": 30486,
                                                            "is_parallel": true,
                                                            "self": 5.5751773056108505,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 4.850817394675687,
                                                                    "count": 60972,
                                                                    "is_parallel": true,
                                                                    "self": 4.850817394675687
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 3.779993858188391e-05,
                    "count": 1,
                    "self": 3.779993858188391e-05,
                    "children": {
                        "thread_root": {
                            "total": 0.0,
                            "count": 0,
                            "is_parallel": true,
                            "self": 0.0,
                            "children": {
                                "trainer_advance": {
                                    "total": 517.5686501031741,
                                    "count": 10713,
                                    "is_parallel": true,
                                    "self": 2.193355308729224,
                                    "children": {
                                        "process_trajectory": {
                                            "total": 166.351602594601,
                                            "count": 10713,
                                            "is_parallel": true,
                                            "self": 166.351602594601
                                        },
                                        "_update_policy": {
                                            "total": 349.02369219984394,
                                            "count": 103,
                                            "is_parallel": true,
                                            "self": 56.517889801296405,
                                            "children": {
                                                "TorchPPOOptimizer.update": {
                                                    "total": 292.50580239854753,
                                                    "count": 16965,
                                                    "is_parallel": true,
                                                    "self": 292.50580239854753
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.16065340000204742,
                    "count": 1,
                    "self": 0.001257800031453371,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.15939559997059405,
                            "count": 1,
                            "self": 0.15939559997059405
                        }
                    }
                }
            }
        }
    }
}